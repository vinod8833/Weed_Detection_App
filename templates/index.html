<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Real-Time Weed Detection</title>    
    <link href="https://cdn.bootcss.com/bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">

    <link rel="stylesheet" href="/static/css/styles.css">

    <style>
              
    </style>
</head>

<body>
    <nav class="navbar navbar-dark bg-dark">
        <div class="container">
            <a class="navbar-brand" href="#">ðŸŒ¿ ðŸŒ¾ WeedScan</a> 
            <button class="btn btn-outline-secondary my-2 my-sm-0" type="button" onclick="location.href='templates/Developers.html'">Developers</button>
          
            
        </div>
    </nav>

    <div class="container-fluid">
        <div class="row">
            <div id="upload-section"  class="col-md-12 upload-section">
                <h2>Upload an Image for Detection</h2>
                <p>Crop and weed detection is based on yolo model with custom training of images
                </p>
                <input type="file" id="file-input"  class="form-control-file" accept="image/*" style="max-width:40%; margin: 0 auto;">
                <button id="upload-button" class="btn">Upload</button>
                <div id="output-container" style="margin-top: 20px;"></div>
                </div>
        </div>
        
        <div class="row">
            <div class="col-md-6 col-12 video-feed">
                <h4>Real-Time Weed Detection Input</h4>
                <div>
                    <video id="videoFeed" class="img-fluid" autoplay playsinline></video>
                </div>
                <button class="btn" id="startDetectionBtn">Start Real-Time Detection</button>
                <button class="btn" id="stopDetectionBtn" style="display: none;">Stop Real-Time Detection</button>
            </div>
            <div class="col-md-6 col-12 video-feed">
                <h4>Real-Time Weed Detection Output</h4>
                <video id="videoFeedOut" class="img-fluid" autoplay playsinline></video>
            </div>
        </div>
    </div>

    <footer>
        <p>&copy; 2024 Real-Time Weed Detection. All rights reserved.</p>
    </footer>

    <script src="/static/js/script.js"></script>
  
    <script>
        const uploadButton = document.getElementById('upload-button');
        const fileInput = document.getElementById('file-input');
        const outputContainer = document.getElementById('output-container');
    
            
        const videoFeed = document.getElementById('videoFeed');
        const videoFeedOut = document.getElementById('videoFeedOut');
    
        const startDetectionBtn = document.getElementById('startDetectionBtn');
        const stopDetectionBtn = document.getElementById('stopDetectionBtn');
        let stream;
        let intervalId;
    
        function speakText(text) {
            // Check if the browser supports SpeechSynthesis API
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
        
                // Set speech parameters (optional)
                utterance.rate = 1;     // Speed (0.1 to 10)
                utterance.pitch = 1;    // Pitch (0 to 2)
                utterance.volume = 1;   // Volume (0 to 1)
        
                // Speak the text
                speechSynthesis.speak(utterance);
        
                // Add event listener for when the speech ends
                utterance.onend = function() {
                    console.log("Speech has ended");
                };
        
            } else {
                console.log("Sorry, your browser does not support speech synthesis.");
            }
        }
    
    
        async function upload_image(file){
            const formData = new FormData();
            formData.append('file', file, 'frame.jpg');
    
            try {
                const response = await fetch('/upload_image', {
                    method: 'POST',
                    body: formData,
                });
    
                if (!response.ok) {
                    throw new Error('Failed to upload image');
                }
    
                const jsonResponse = await response.json();
                const processedImageBase64 = jsonResponse.image;
                const cropCount = jsonResponse.crop_count;
                const weedCount = jsonResponse.weed_count;
    
                console.log('Crops detected:', cropCount);
                console.log('Weeds detected:', weedCount);
    
                if (cropCount > 0) {
                   // const cropSound = new Audio('/static/audio/crop.mp3');  
                   // cropSound.play();
                    speakText(`Total ${cropCount} crops detected`);
    
                }
                
                if (weedCount > 0) {
                    //const weedSound = new Audio('/static/audio/weed.mp3');
                   // weedSound.play();
    
                    speakText(`Total ${weedCount} weeds detected`);
                }
    
                // Convert Base64 image to Blob and display on canvas
                const processedImageBlob = await fetch(`data:image/jpeg;base64,${processedImageBase64}`).then(res => res.blob());
                const url = URL.createObjectURL(processedImageBlob);
                return url;
            } catch (error) {
                console.error(error);
                alert('An error occurred while uploading the image');
            }
            
        }
    
    
        async function startRealTimeDetection() {
            const constraints = {
                video: {
                    facingMode: 'environment' // Use 'user' for front camera, 'environment' for back camera
                }
            };
    
            try {
                stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoFeed.srcObject = stream;
                startDetectionBtn.style.display = 'none';
                stopDetectionBtn.style.display = 'block';
    
                sendVideoFrames();
            } catch (error) {
                console.error('Error accessing the camera: ', error);
                alert('Unable to access the camera. Please check permissions.');
            }
        }
    
        function stopRealTimeDetection() {
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                videoFeed.srcObject = null;
            }
            clearInterval(intervalId);
            startDetectionBtn.style.display = 'block';
            stopDetectionBtn.style.display = 'none';
        }
    
    
        function sendVideoFrames() {
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            
            const outputCanvas = document.createElement('canvas');
            const outputContext = outputCanvas.getContext('2d');
    
            function updateCanvasSize() {
                canvas.width = videoFeed.videoWidth || 640;
                canvas.height = videoFeed.videoHeight || 480;
    
                outputCanvas.width = canvas.width;
                outputCanvas.height = canvas.height;
            }
    
            // Call this once to set the initial size
            updateCanvasSize();
    
            intervalId = setInterval(async () => {
                // Check if video is playing and the dimensions are available
                if (!videoFeed.paused && !videoFeed.ended && videoFeed.videoWidth > 0 && videoFeed.videoHeight > 0) {
                    context.drawImage(videoFeed, 0, 0, canvas.width, canvas.height);
    
                    // Create a blob from the canvas
                    const blob = await new Promise((resolve, reject) => {
                        canvas.toBlob((b) => {
                            if (b) {
                                resolve(b);
                            } else {
                                reject(new Error("Failed to create blob from canvas."));
                            }
                        }, 'image/jpeg');
                    });
    
                    if (!blob) {
                        console.error('Blob creation failed.');
                        return; 
                    }
    
                    const url = await upload_image(blob);
                        
                    // Draw the processed image onto the output canvas
                    const img = new Image();
                    img.onload = () => {
                        outputContext.clearRect(0, 0, outputCanvas.width, outputCanvas.height); // Clear previous image
                        outputContext.drawImage(img, 0, 0, outputCanvas.width, outputCanvas.height);
                        // Now draw the output canvas onto the video feed
                        context.drawImage(outputCanvas, 0, 0, canvas.width, canvas.height);
                        videoFeedOut.srcObject = outputCanvas.captureStream();
    
                    };
                    img.src = url;
                } else {
                    console.warn('Video is not playing or dimensions are not available.');
                }
            }, 1000); // in milliseconds
        }
    
    
        uploadButton.addEventListener('click', async () => {
            const file = fileInput.files[0];
            if (!file) {
                alert('Please select an image to upload');
                return;
            }
    
            const url = await upload_image(file);  
            outputContainer.innerHTML = `<h3>Detection Result:</h3><img src="${url}" alt="Detected Image" style="max-width: 100%;">`;
           
        });
    
    
        startDetectionBtn.addEventListener('click', startRealTimeDetection);
        stopDetectionBtn.addEventListener('click', stopRealTimeDetection);
    
        videoFeed.addEventListener('loadeddata', () => {
            sendVideoFrames();
        });
    
  </script>    
</body>
</html>
